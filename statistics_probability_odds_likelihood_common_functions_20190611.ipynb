{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "latex symbols\n",
    "https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logit and logistic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/34636/interpretation-of-simple-predictions-to-odds-ratios-in-logistic-regression\n",
    "\n",
    "### probabilities and odds, \n",
    "\n",
    "example of flipping coins: total flips = 100, heads=45, tails=55.\n",
    "\n",
    "calculate probability and odds of seeing heads:\n",
    "\n",
    "\n",
    "$probability = \\frac{number\\_of\\_heads}{total\\_flips}=\\frac{45}{100}=0.45$, probaility < [0,1]\n",
    "\n",
    "$odds = \\frac{number\\_of\\_heads}{number\\_of\\_non_heads}=\\frac{45}{55}=0.818$,or expressed as 45:55 (Las Vagas odds), odds < (0,+∞)\n",
    "\n",
    "we can convert between odds and probabilities:\n",
    "\n",
    "$ probability = \\frac{odds}{1 + odds}=\\frac{\\frac{45}{55}}{1+ \\frac{45}{55}}=\\frac{45}{55+45}=0.45 $\n",
    "\n",
    "$ odds = \\frac{probability} {1 - probability} =\\frac{\\frac{45}{100}}{1 - \\frac{45}{100}} = \\frac{45}{100-45}=0.818$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, the logit function or the log-odds is the logarithm of the odds p/(1 − p) where p is the probability. It is a type of function that creates a map of probability values from ${\\displaystyle [0,1]} [0,1] to {\\displaystyle [-\\infty ,+\\infty ]} [-\\infty, +\\infty]$. It is the inverse of the sigmoid function or logistic transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probability and likelihood\n",
    "For a continous random variable, if we know it falls in a normal distribution (or any other distribution), which can be described as mean(mu, average value) and stardand deviation (sigma how spread), We could estimate the probability of observing the data in a range. For example, we know the average weight of Macdonald big Mac is 0.25 pound, standard deviation is 0.05. Also the weight follows a normal distribuation. then we can ask what is the probability of seeing a big Mac weighing between 0.27 to 0.28 pound. The area under the probability density curve between 0.27 and 0.28 is the probability, which is 0.2. P(big Mac=0.27 to 0.28|normal distribution mu=0.25, sd=0.2) = 0.2. The probability of a randomly selected big Mac weighign 0.27 to 0.28 pounds is 0.2. So you know or assume the data follow a distribution, then integral/ area tells you the probability of the observed data.  \n",
    "\n",
    "On the other hand, if you randomly weighted a big Mac and found its weight is 0.275, you want to know how likely this big Mac is from a specific distribution, for example, $N(\\mu=0.25, \\sigma^2=0.2)$. L(normal distribution(mu=0.25, sd=0.2)|big Mac=0.275). you look up the pdf and find x=0.275 the likelihood is 0.17. this tells you that teh likelihood the big Mac is from this distrution is 0.17. keep in mind, if you have another distribution, say mu=0.275, sigma=0.2, then the likelihood this big Mac if from this new distribution is higher, 0.21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pmf (probability mass function) and pdf (probability density function)\n",
    "pmf is for discrete random variable x. x can only be a set of finite discrete values.  Y shows probabilites of each possible outcome. Sum of all probabilities is 1.\n",
    "\n",
    "pdf is for continous random variable x. x is continous and can take inifite values. Therefore the probability of each value is 0. In a pdf, the Y is not probability. It is probability/length unit. The integral, the area under the pdf curve in a range a and b is the probability of seeing the outcome between a and b. For example, the weight of a Macdonald hamberger is a continous random variable.  assume the weight is 0.25 pound and follow a normal distribution. The probability of seeing hamberger weighing 0.28 to 0.29 is the area under the pdf and above the x and between 0.28 and 0.29, 20% for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic function, sigmoid function, logit function, softmax function\n",
    "sigmoid function is a special form of logistic function when L=1, k=1, and x0=0.\n",
    "\n",
    "$logistic\\ function: f(x) = \\frac{L}{1 + e^{-k(x-x_0)}},\\ f(x) \\in (0, L)$\n",
    "\n",
    "$sigmoid\\ function: \\sigma(x) = \\frac{1}{1 + e^{-x}},\\ \\sigma(x) \\in (0,1)$\n",
    "\n",
    "$ softmax\\ function:  \\sigma (z)_i=\\frac{e^{z_{i}}}{\\sum _{j=1}^{K}e^{z_{j}}},\\ \\sigma(z)_i \\in(0,1)$ for i = 1, …, K and $z =(z_{1},\\ldots ,z_{K})$\n",
    "\n",
    "\n",
    "$logit\\ function = log\\_odds = logarithm\\ of\\ the\\ odds = logit(p) = log(\\frac{p}{1 - p}) $. It maps the probability from $[0, 1]$ to $[-\\infty, +\\infty]$. It is the inverse of the sigmoid function or logistic function.\n",
    "\n",
    "$\\sigma(logit(p)) = p$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.columbia.edu/~so33/SusDev/Lecture_9.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central limit therom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with ANY distribution with a defined mean and standard deviation. If we draw samples (for example 100 samples) from the distribution and calculate the mean of the sample, the sampling distribution of the sample means will approximate a normal distribution if the sample size n is sufficiently large.\n",
    "\n",
    "The mean of all the samples taken from the population is a good approximation to the mean of the population if the sample size is sufficiently large. The original population does not need to be normally distributed. The sampling distribution of the mean is normally distributed when the n is sufficiently big. \n",
    "Rolling a dice 500x. Flat distribution, all numbers roughly equal. Rolling 50 times and calculate the mean and repeat 500 times. Look at the mean distribution, should be normal.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' therom and Baysian statistical analysis\n",
    "conditional probability, joint probability, and marginal probability. conditional probabity and joint probability is different, P(A, B) = P(A|B)*P(B) != P(A|B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example to illustrate this\n",
    "##### For example, we surveyed 100 people and found 30 peole had cancer, 70 people had no-cancer. Also, 50 people tested for HIV+ and 50 people HIV-. We summarize the results in the following contigency table. \n",
    "\n",
    "|category|HIV+|HIV-|\n",
    "|---|---|---|\n",
    "|Cancer|20|10|\n",
    "|non_cancer|30|40|\n",
    "\n",
    "\n",
    "##### Based on this survey, we can say.\n",
    "* P(cancer) = 0.3\n",
    "* P(no-cancer) = 0.7\n",
    "* P(HIV) = 0.5\n",
    "* P(noHIV) = 0.5\n",
    "\n",
    "##### below are conditional probability. given something has occurred, what is the probability somethinge else happens.\n",
    "\n",
    "* P(cancer|HIV) = 0.4 probability of having cancer given the person has already had HIV is 0.4 \n",
    "* P(cancer|noHIV) = 0.2\n",
    "* P(HIV|cancer) = 0.67\n",
    "* P(onHIV|cancer) = 0.33\n",
    "* P(no-cancer|HIV) = 0.6\n",
    "\n",
    "##### joint probability, this is different from conditional probability\n",
    "$P(A\\cap B) = P(A|B) * P(B)$\n",
    "\n",
    "* P(cancer and HIV) = 0.2 = P(cancer|HIV) x P(HIV) = 0.4 x 0.5 = 0.2\n",
    "\n",
    "##### Bayes' therom:\n",
    "\n",
    "$ P(A|B) = \\frac{P(B|A) * P(A)}{P(B)}$\n",
    "\n",
    "$ P(B) = P(B\\cap A) + P(B\\cap A^c)$ this is also called marginal probability\n",
    "\n",
    "##### let's convince ourselves that it is true in this case:\n",
    "$$ \n",
    "\\begin{align}\n",
    "P(B) &=P(HIV) \\\\\n",
    "&= P(B\\cap A) + P(B\\cap A^c)\\\\ \n",
    "&= P(HIV\\cap caner) + P(HIV\\cap no-cancer)\\\\\n",
    "&= 0.2 + 0.3 \\\\\n",
    "&= 0.5\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "##### this can also be calculated as below. this is in fact how it is done in Baysian statistic analysis.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "P(B) &=P(HIV) \\\\&= P(B\\cap A) + P(B\\cap A^c)\\\\ &= P(HIV\\cap caner) + P(HIV\\cap no-cancer)\\\\ \n",
    "&=P(HIV\\cap caner) + P(HIV\\cap no-cancer)\\\\\n",
    "&= P(HIV|cancer)\\times P(cancer) + P(HIV|no-cancer)\\times P(no-cancer)\\\\\n",
    "&=\\frac{2}{3}\\times 0.3+\\frac{3}{7}\\times 0.7\\\\\n",
    "&= 0.5\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "##### Now. let's us Bayes' therom to update our belief:\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A|B) &=P(cancer|HIV)\\\\\n",
    "&=\\frac{P(B|A) \\times P(A)}{P(B)} \\\\\n",
    "&=\\frac{P(HIV|cancer) \\times P(cancer)}{P(HIV)} \\\\\n",
    "&= \\frac{\\frac{2}{3}\\times0.3}{0.5}\\\\\n",
    "&=0.4\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "##### this shows Bayes's therom can weigh in new evidence and update our belief. To start with, our prior belief is that a person has 30% chance to have cancer. new evidence emerged that this person contracted HIV. Based on this new information, Bayes' therom can update our initial belief and tell us the person's chance of having cancer is 40% now. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cancer distribution in HIV+ and HIV- is different. If we picked a person with cancer, how probable is this person from the HIV+ group?\n",
    "\n",
    "|caner?|HIV+|---|caner?|HIV-|\n",
    "|---|---|---|---|---|\n",
    "|Cancer|20|---|Cancer|10|\n",
    "|non_cancer|30|---|non_cancer|40|\n",
    "\n",
    "Intuitively, we think it is more likely the person is from HIV+ because 40% people have cancer in HIV+ and only 20% people in HIV- group have cancer. but how more probably?\n",
    "\n",
    "hypothesis H1: from HIV+\n",
    "\n",
    "hypothesis H2: from HIV_\n",
    "\n",
    "prior: we intial belief the patient is equally likely from each group. P(H1) = P(H2) = 0.5\n",
    "\n",
    "evidence E: picked a person having cancer\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(H1|E) &= \\frac{P(E|H1)\\times P(H1)}{P(E)}\\\\\n",
    "&=\\frac{P(E|H1)\\times P(H1)}{P(E|H1)\\times P(H1) + P(E|H2)\\times P(H2)}\\\\\n",
    "&=\\frac{0.4\\times 0.5}{0.4\\times 0.5 + 0.2\\times 0.5}\\\\\n",
    "&=0.67\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(sleep|light\\_on)=\\frac{p(light\\_on|sleep)*p(sleep)}{p(light\\_on\\cap sleep)+p(light\\_on \\cap nonsleep)}=\\frac{p(light\\_on|sleep)*p(sleep)}{p(light\\_on | sleep)*p(sleep) + p(light\\_on|nonsleep)*p(nonsleep)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769230769230769"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75/130"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
